{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e534e3-90e8-4d2c-9c02-814ed7962a8f",
   "metadata": {},
   "source": [
    "# Simple Cloud storage operations with gcsfs\n",
    "\n",
    "So somebody (it was me wasn't it?) told you to `put your data on a LEAP cloud bucket` but it is not entirely clear how to do that. \n",
    "\n",
    "Lets explore how we would go about it and what the benefits are.\n",
    "\n",
    "Cloud Storage works quite differently from a traditional filesystem (e.g. on an HPC or the harddrive on your laptop). \n",
    "> Cloud object storage is essentially a key/value storage system. They keys are strings, and the values are bytes of data. Data is read and written using HTTP calls.\n",
    "\n",
    "[2i2c docs](https://docs.2i2c.org/user/topics/data/cloud/#cloud-object-storage)\n",
    "\n",
    "This means that we need to tweak the way we read and write data accordingly. But as you will see the changes are fairly small when working with xarray datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84329f3a-6ec8-4e26-a3f5-edc06659df42",
   "metadata": {},
   "source": [
    "## Creating a small test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed75021-2ea9-4e6b-b3f7-02c39be0292c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# lets make a test dataset\n",
    "ds = xr.DataArray(...).to_dataset(name='data')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f9aca-d460-4125-9c6d-77fe3e0e85b4",
   "metadata": {},
   "source": [
    "## Save a netcdf to your user directory (Only for small test files!)\n",
    "\n",
    "So we can naively start to save our data as we would e.g. on our laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163e1880-6092-4b48-93e2-81fbc040fde0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.to_netcdf(...)\n",
    "\n",
    "# we can reload the file with\n",
    "\n",
    "ds_reloaded = xr.open_dataset(...)\n",
    "ds_reloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507249a-4d26-4255-b7e9-486d711dd27d",
   "metadata": {},
   "source": [
    "This works fine for small test datasets like the one above, but has several downsides\n",
    "\n",
    "‚ùå Nobody but you can read this file\n",
    "\n",
    "‚ùå The User Directory can not be used for large files!\n",
    "\n",
    "## Now let's move the file to a cloud bucket\n",
    "Ok so the next best thing is to create a small file locally and then put it into a bucket. \n",
    "\n",
    "We can use the gcsfs library to get some 'filesystem-like' convienence on top of our cloud object store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a93273-ae31-43c2-8868-dd25e878f354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "fs.ls('gs://leap-scratch') # methods are similar to UNIX shell commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88615d1e-4c34-4ce6-965a-6eeffb990fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# üö® Always work in a subfolder with your username, to avoid messing with other folks data\n",
    "import os\n",
    "user_path = f\"gs://leap-scratch/{os.environ['JUPYTERHUB_USER']}/site_visit_demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac5595c-7890-47bf-bd90-d110515af7f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can put our written netcdf on the cloud bucket with the .put method\n",
    "cloud_path = user_path+...\n",
    "fs.put(..., cloud_path)\n",
    "fs.ls(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f93e20-0a8a-4aab-820b-d2b7bc6096e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can now load the netcdf file from the cloud bucket using xarray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98018c01-d636-4c02-86db-27d9d64c0c03",
   "metadata": {},
   "source": [
    "So big deal, what is the advantage of this? \n",
    "\n",
    "You can now share the following snipped with everyone in LEAP and they can access the file! Lets try it with my version.\n",
    "\n",
    "```python\n",
    "import xarray as xr\n",
    "import gcsfs \n",
    "fs = gcsfs.GCSFileSystem()\n",
    "cloud_path = 'gs://leap-scratch/jbusecke/annual_meeting_demo/netcdf_upload/first.nc'\n",
    "with fs.open(cloud_path) as f:\n",
    "    ds_julius = xr.open_dataset(f)\n",
    "ds_julius\n",
    "```\n",
    "üëÜ copy this into a new cell and execute it!\n",
    "\n",
    "----\n",
    "\n",
    "Ok so we just showed that with this simple change we can keep working as before, but we also gained the ability to easily share data with other LEAP members!\n",
    "\n",
    "However this approach is still not optimal. Instead whenever you have array data as an xarray Dataset we strongly recommend to use [zarr](https://zarr.dev) which is optimized for cloud object storage and enables you to write directly to cloud storage in a streaming fashion (eliminating the need for intermediate copies of your files) and under the right conditions can enable much better performance for distributed data analytics in the cloud. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c149870-7cf9-4603-9460-9faa26e42f96",
   "metadata": {},
   "source": [
    "## Writing to zarr instead of netcdf\n",
    "\n",
    "You will see that when you use zarr\n",
    "- The code becomes even cleaner\n",
    "- And there might be big performance gains over netcdf files when you work with large datasets. \n",
    "\n",
    "So lets redo the whole thing with zarr!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722b7c59-18d3-4f9f-8994-cf45cde4dace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cloud_path_zarr = user_path+...\n",
    "ds.attrs['zarr']='FTW' # lets give this dataset a unique attribute \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555c440-687c-4f74-b2cf-902627fe3683",
   "metadata": {},
   "source": [
    "Thats it! \n",
    "\n",
    "By giving a url which starts with `gs://...` xarray automatically invokes `gcsfs` under the hood!\n",
    "\n",
    "You can now give your collaborator an even more concise snippet:\n",
    "```python\n",
    "import xarray as xr\n",
    "path = 'gs://leap-scratch/jbusecke/annual_meeting_demo/zarr_write/first.zarr'\n",
    "ds_julius_zarr = xr.open_dataset(path, engine='zarr')\n",
    "ds_julius_zarr\n",
    "```\n",
    "\n",
    "Feel free to try this out again! Check the datasets attributes.\n",
    "\n",
    "## Take Home Points\n",
    "‚úÖ Moving data to the cloud buckets enables you to share data with other LEAP members super easily.\n",
    "\n",
    "‚úÖ Whenever you are able to load data into an xarray dataset, try to use `.to_zarr()` to store a cloud optimized zarr store into a cloud bucket!\n",
    "\n",
    "‚ö†Ô∏è All data on the buckets are visible to all members, but do not just use data from other users without contacting them. \n",
    "\n",
    "‚ö†Ô∏è The LEAP cloud buckets are **not meant as long-term archival storage**. Always have a backup copy of valuable data on another resource!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
